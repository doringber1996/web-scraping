# web-scraping
# An assignment during my 3rd year
מטלה 4: web scraping
שימו לב: מטלה זו היא מטלה מקדימה למטלה המסכמת. כלומר המטלה המסכמת תתבסס על תוצאות מטלה זה.
במטלה נאסוף דאטה על דירות למכירה ומחירים מבוקשים מאתר מדל"ן באמצעות scraping
עליכם לכתוב crawler שעובר על האתר של מדלן  ואוסף נכסים מהעיר שבה אתם גרים (או עיר אחרת שבה הייתם רוצים לגור).
למשל אם העיר היה רעננה, אזי יש לשלוף נתונים מהכתובת:
https://www.madlan.co.il/for-sale/רעננה-ישראל
אם העיר היא תל אביב, אזי יש לשלוף נתונים מהכתובת:
https://www.madlan.co.il/for-sale/תל-אביב-ישראל 

כדי לדמות את הבקשה שלנו לבקשה שמגיעה מדפדפן יש להגדיר headers בתוך הבקשה באופן הבא:
headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/113.0.0.0 Safari/537.36'}  # This is chrome, you can set whatever browser you like
response = requests.get(url,headers= headers)

יש ליצור מהנתונים שאתם אוספים dataframe  במבנה הבא (יש להקפיד על שמות השדות בדיוק כפי שמופיע כאן):

•	City – עיר הנכס
•	type – סוג הנכס – דירה/בית פרטי/קוטג'
•	room_number – מספר חדרים
•	Area – שטח הדירה
•	Street – שם הרחוב
•	number_in_street – מספר ברחוב
•	city_area – האיזור בעיר
•	price – מחיר הנכס (המשתנה התלוי)
בונוס: השדות הבאים נמצאים בדף הנכס
•	num_of_images – מספר התמונות של הנכס שצורפו
•	floor_out_of  - קומה מתוך כמה קומות
•	hasElevator – האם יש מעלית
•	hasParking – האם יש חניה
•	hasBars – יש סורגים
•	hasStorage – יש מחסן
•	condition – מצב הנכס (משופץ/דורש שיפוץ/שמור... (
•	hasAirCondition = יש מזגן
•	hasBalcony = יש מרפסת
•	hasMamad = יש ממד
•	handicapFriendly – נגיש לנכים
•	entranceDate – תאריך כניסה
•	furniture – כולל ריהוט (חלקי/כן/לא)
•	publishedDays – מספר ימים שההודעה מפורסמת
•	description – תיאור הנכס

הערות

1.	שימו לב: יתכן שלנכסים שונים יהיו ערכים מסוימים חסרים – זה בסדר להשאיר תאים ריקים אם לא מופיע עבורם ערך באתר.
2.	במקרים שמדובר בשדות בוליאנים (hasParking, או hasElevator למשל) אם אין ערך בשדה – נשים False.
3.	כדי למנוע מצב שהאתר חוסם אתכם – כדאי לשמור את הhtml response כקובץ בפעם הראשונה ואז לגשת אליו ולא לבצע שוב ושוב בקשות GET לאתר, כך שבסוף תחסמו. 
4.	יש לשמור את ה – dataframe בקובץ CSV או XSLS
5.	יש להגיש במודל:
a.	מחברת הכוללת את קוד ה – crawler
b.	קובץ CSV או XSLS הכולל את הפרטים של לפחות 10 נכסים. אם לא הצלחתם לאסוף את כל הנכסים באופן ממוחשב – יש למלא אותם באופן ידני מהאתר (לטובת המשך המטלה)
6.	ניתן לבצע את המטלה בזוגות.

